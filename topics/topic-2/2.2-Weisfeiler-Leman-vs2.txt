Chapter II: Graph Similarity
II.2: Weisfeiler-Leman Approaches
Professor Dr. Petra Mutzel
Abteilung fur Computational Analytics ¨
Institut fur Informatik (Abt. 1) ¨
Universit¨at Bonn
WiSe 2025/26 VO 6/7 17/24 November 2025
1 / 47
Outline
1 Introduction
Original Weisfeiler-Leman Algorithm
Properties of the WL Algorithm
Efficient WL Algorithm
2 k-dimensional WL Algorithm on Sets
3 Local k-WL on Sets
4 WL for Data Analysis
Classification with WL
Introduction Weisfeiler-Leman Algorithm
Classification with WL
Idea: Combination of WL with similarity measures
Construct feature vector for each graph
e.g. after each round: sort the vertices according to colors, vector gets
information of number of vertices with color c
append these (possibly weighted) vectors to each other
Φ(G) = (3, 1, 1) Φ(H) = (3, 1, 1) Φ(G) = (3, 1, 1, 2, 0, 0, 1, 1, 1, 0) Φ(H) = (3, 1, 1, 2, 1, 1, 0, 0, 0, 1)
7 / 47
Introduction Weisfeiler-Leman Algorithm
Classification with WL
Idea: Combination of WL with similarity measures
Construct feature vector for each graph
e.g. after each round: sort the vertices according to colors, vector gets
information of number of vertices with color c
append these (possibly weighted) vectors to each other
Φ(G) = (3, 1, 1) Φ(H) = (3, 1, 1) Φ(G) = (3, 1, 1, 2, 0, 0, 1, 1, 1, 0) Φ(H) = (3, 1, 1, 2, 1, 1, 0, 0, 0, 1)
→ Similarity measure based on graph kernel, Jaccard-Coefficient, ...
7 / 47
Introduction Weisfeiler-Leman Algorithm
Graph Embedding
feature vector feature space
Generate a feature vector for each graph in the given graph data set
Use your favorite (data) classification/clustering method
Sources: https://www.kdd.org/kdd2019/accepted-papers/view/learning-interpretable-metric-between-graphs-convexformulation-and-computa
8 / 47
Introduction Weisfeiler-Leman Algorithm
Recognition of Cuneiform Characters
right vertex
left vertex
tail vertex
depth vertex
500.000 digitized cuneiform fragments (LS7, TU Dortmund)
group of wedge signs corresponds to a character
so far 1000 different characters known
only a very small set of cuneiform characters have been classified
Goal: Recognition of cuneiform characters for supporting classic
Altphilologists
Kriege, Fey, Fisseler, Mutzel, Weichert: COST, Proc. MLR 2018
DFG SFB 876: Providing Information by Resource-Constrained Data Analysis
9 / 47
Introduction Weisfeiler-Leman Algorithm
Protein Complex Similarity
suggest similarity measures based on WL algorithm for protein
complexes
first run WL, then apply Jaccard similarity coefficient (def. for
multisets: size of bag intersection divided by size of bag sum)
evaluation on 500 000 simulated complexes of the human adhesome
protein network
→ in agreement with graph edit similarity
St¨ocker, Sch¨afer, Mutzel, K¨oster, Kriege, Rahmann: SISAP 2019
DFG SFB 876: Providing Information by Resource-Constrained Data Analysis
10 / 47
Introduction Properties of WL
1 Introduction
Original Weisfeiler-Leman Algorithm
Properties of the WL Algorithm
Efficient WL Algorithm
2 k-dimensional WL Algorithm on Sets
3 Local k-WL on Sets
4 WL for Data Analysis
Classification with WL
11 / 47
Introduction Properties of WL
Isomorphism Test using Weisfeiler-Leman
One-Sided Isomorphism Test
Apply WL to the two graphs G and H simultaneously
If G and H get different colors =⇒ G ̸≃ H
⇒ WL distinguishes G and H
Otherwise: we do not know whether G and H are isomorphic
G H G H G H
Initialization Iteration 1 Iteration 2
11 / 47
Introduction Properties of WL
Isomorphism Test using Weisfeiler-Leman
Properties of WL
WL can identify all forests, i.e., non-isomorphic forests get different
colors
12 / 47
Introduction Properties of WL
Isomorphism Test using Weisfeiler-Leman
Properties of WL
WL can identify all forests, i.e., non-isomorphic forests get different
colors
random graphs G will be identified correctly with high probability
12 / 47
Introduction Properties of WL
Isomorphism Test using Weisfeiler-Leman
Properties of WL
WL can identify all forests, i.e., non-isomorphic forests get different
colors
random graphs G will be identified correctly with high probability
cannot distinguish regular graphs (same degree) → same color
12 / 47
Introduction Properties of WL
Isomorphism Test using Weisfeiler-Leman
G H
Properties of WL
WL can identify all forests, i.e., non-isomorphic forests get different
colors
random graphs G will be identified correctly with high probability
cannot distinguish regular graphs (same degree) → same color
12 / 47
Introduction Properties of WL
Partitions generated by Weisfeiler-Leman
Definitions (Partitions)
The colour classes calculated in every iteration by WL naturally
partition the vertices of the input graph G.
G H
Initialization Iteration 1 Iteration 2
13 / 47
Introduction Properties of WL
Partitions generated by Weisfeiler-Leman
Definitions (Partitions)
The colour classes calculated in every iteration by WL naturally
partition the vertices of the input graph G.
For such a partition π we call {C1, C2, . . . , Cs} the cells of π.
G H G H
Initialization Iteration 1 Iteration 2
13 / 47
Introduction Properties of WL
Partitions generated by Weisfeiler-Leman
Definitions (Partitions)
The colour classes calculated in every iteration by WL naturally
partition the vertices of the input graph G.
For such a partition π we call {C1, C2, . . . , Cs} the cells of π.
A partition ρ refines a partition π if for every pair of vertices u, v ∈ V
in the same cell of ρ the two vertices also share one cell in π.
G H G H G H
Initialization Iteration 1 Iteration 2
13 / 47
Introduction Properties of WL
Partitions generated by Weisfeiler-Leman
Definitions (Partitions)
The colour classes calculated in every iteration by WL naturally
partition the vertices of the input graph G.
For such a partition π we call {C1, C2, . . . , Cs} the cells of π.
A partition ρ refines a partition π if for every pair of vertices u, v ∈ V
in the same cell of ρ the two vertices also share one cell in π.
A partition π is stable (equitable) for G if for every pair of vertices
u, v ∈ V in the same cell and a cell R ∈ π we have:
|N(u) ∩ R| = |N(v) ∩ R|, where N(u) is the set of neighbors of u
G H G H G H
Initialization Iteration 1 Iteration 2
13 / 47
Introduction Properties of WL
Refining WL Partitions
G H G H G H G H
Initialization Iteration 1: π Iteration 2: π
′
Iteration 3: ρ
14 / 47
Introduction Properties of WL
Refining WL Partitions
Definition (Refining operation (R, S))
G H G H G H G H
Initialization Iteration 1: π Iteration 2: π
′
Iteration 3: ρ
14 / 47
Introduction Properties of WL
Refining WL Partitions
Definition (Refining operation (R, S))
Let R and S be two (not necessarily distinct) cells in a partition π.
G H G H G H G H
Initialization Iteration 1: π Iteration 2: π
′
Iteration 3: ρ
14 / 47
Introduction Properties of WL
Refining WL Partitions
Definition (Refining operation (R, S))
Let R and S be two (not necessarily distinct) cells in a partition π.
A refining operation (R, S) refines the partition π by splitting the
vertex set S into finer color classes by calculating the number dR(u)
of neighbors in the set R for every u ∈ S; two vertices will receive
different colors if those numbers differ.
G H G H G H G H
Initialization Iteration 1: π Iteration 2: π
′
Iteration 3: ρ
14 / 47
Introduction Properties of WL
Refining WL Partitions
Definition (Refining operation (R, S))
Let R and S be two (not necessarily distinct) cells in a partition π.
A refining operation (R, S) refines the partition π by splitting the
vertex set S into finer color classes by calculating the number dR(u)
of neighbors in the set R for every u ∈ S; two vertices will receive
different colors if those numbers differ.
R is called the refining set.
G H G H G H G H
Initialization Iteration 1: π Iteration 2: π
′
Iteration 3: ρ
14 / 47
Introduction Properties of WL
Refining WL Partitions
Definition (Refining operation (R, S))
Let R and S be two (not necessarily distinct) cells in a partition π.
A refining operation (R, S) refines the partition π by splitting the
vertex set S into finer color classes by calculating the number dR(u)
of neighbors in the set R for every u ∈ S; two vertices will receive
different colors if those numbers differ.
R is called the refining set.
We denote the degree of a vertex u w.r.t. a cell R as dR(u).
G H G H G H G H
Initialization Iteration 1: π Iteration 2: π
′
Iteration 3: ρ
14 / 47
Introduction Properties of WL
Properties of WL Partitions
Lemma 1
Let partition π
′ be obtained from π by a refining operation (R,S).
G H G H G H G H
Initialization Iteration 1: π Iteration 2: π
′
Iteration 3: ρ
15 / 47
Introduction Properties of WL
Properties of WL Partitions
Lemma 1
Let partition π
′ be obtained from π by a refining operation (R,S).
If ρ is a stable partition with ρ refines π, then we also have that ρ
refines π
′
.
G H G H G H G H
Initialization Iteration 1: π Iteration 2: π
′
Iteration 3: ρ
15 / 47
Introduction Properties of WL
Properties of WL Partitions
Lemma 1
Let partition π
′ be obtained from π by a refining operation (R,S).
If ρ is a stable partition with ρ refines π, then we also have that ρ
refines π
′
.
Proof:
Let u, v ∈ V be in the same cell in ρ, hence also in π.
G H G H G H G H
Initialization Iteration 1: π Iteration 2: π
′
Iteration 3: ρ
15 / 47
Introduction Properties of WL
Properties of WL Partitions
Lemma 1
Let partition π
′ be obtained from π by a refining operation (R,S).
If ρ is a stable partition with ρ refines π, then we also have that ρ
refines π
′
.
Proof:
Let u, v ∈ V be in the same cell in ρ, hence also in π.
For any cell R ∈ π we have dR(u) = dR(v), since R is a union of sets
in ρ and ρ is stable.
G H G H G H G H
Initialization Iteration 1: π Iteration 2: π
′
Iteration 3: ρ
15 / 47
Introduction Properties of WL
Properties of WL Partitions
Definition (Coarsest partition)
A partition ρ is a coarsest partition for a property P if ρ satisfies P,
and there is no partition π ̸= ρ with ρ refines π that also satisfies
property P.
16 / 47
Introduction Properties of WL
Properties of WL Partitions
Definition (Coarsest partition)
A partition ρ is a coarsest partition for a property P if ρ satisfies P,
and there is no partition π ̸= ρ with ρ refines π that also satisfies
property P.
Lemma 2
Let G be a graph. For every partition π of V, there is a unique
coarsest stable partition ρ that refines π.
(without proof)
G H G H G H G H
Initialization Iteration 1: π Iteration 2: π
′
Iteration 3: ρ
16 / 47
Introduction Properties of WL
Equitable Partitions
Let {C1, C2, . . . , Cs} of V(G) be an equitable partition, i.e., for all i and j
and for all u, v ∈ Ci we have: |N(u) ∩ Cj
| = |N(v) ∩ Cj
|.
Observations
17 / 47
Introduction Properties of WL
Equitable Partitions
Let {C1, C2, . . . , Cs} of V(G) be an equitable partition, i.e., for all i and j
and for all u, v ∈ Ci we have: |N(u) ∩ Cj
| = |N(v) ∩ Cj
|.
Observations
every graph has an equitable partition, e.g., every node in extra class
17 / 47
Introduction Properties of WL
Equitable Partitions
Let {C1, C2, . . . , Cs} of V(G) be an equitable partition, i.e., for all i and j
and for all u, v ∈ Ci we have: |N(u) ∩ Cj
| = |N(v) ∩ Cj
|.
Observations
every graph has an equitable partition, e.g., every node in extra class
for regular graphs, C1 = V(G) defines an equitable partition
17 / 47
Introduction Properties of WL
Equitable Partitions
Let {C1, C2, . . . , Cs} of V(G) be an equitable partition, i.e., for all i and j
and for all u, v ∈ Ci we have: |N(u) ∩ Cj
| = |N(v) ∩ Cj
|.
Observations
every graph has an equitable partition, e.g., every node in extra class
for regular graphs, C1 = V(G) defines an equitable partition
Remarks
17 / 47
Introduction Properties of WL
Equitable Partitions
Let {C1, C2, . . . , Cs} of V(G) be an equitable partition, i.e., for all i and j
and for all u, v ∈ Ci we have: |N(u) ∩ Cj
| = |N(v) ∩ Cj
|.
Observations
every graph has an equitable partition, e.g., every node in extra class
for regular graphs, C1 = V(G) defines an equitable partition
Remarks
Equitable partitions are partially ordered under the usual is finer than
relation for partitions.
17 / 47
Introduction Properties of WL
Equitable Partitions
Let {C1, C2, . . . , Cs} of V(G) be an equitable partition, i.e., for all i and j
and for all u, v ∈ Ci we have: |N(u) ∩ Cj
| = |N(v) ∩ Cj
|.
Observations
every graph has an equitable partition, e.g., every node in extra class
for regular graphs, C1 = V(G) defines an equitable partition
Remarks
Equitable partitions are partially ordered under the usual is finer than
relation for partitions.
Equitable partitions of a graph form a lattice.
17 / 47
Introduction Properties of WL
Equitable Partitions
Let {C1, C2, . . . , Cs} of V(G) be an equitable partition, i.e., for all i and j
and for all u, v ∈ Ci we have: |N(u) ∩ Cj
| = |N(v) ∩ Cj
|.
Observations
every graph has an equitable partition, e.g., every node in extra class
for regular graphs, C1 = V(G) defines an equitable partition
Remarks
Equitable partitions are partially ordered under the usual is finer than
relation for partitions.
Equitable partitions of a graph form a lattice.
The maximum element of the equitable partition lattice is the
coarsest equitable partition of G.
17 / 47
Introduction Properties of WL
Coarsest Equitable Partition
Let {C1, C2, . . . , Cs} of V(G) be an equitable partition, i.e., for all i and j
and for all u, v ∈ Ci we have: |N(u) ∩ Cj
| = |N(v) ∩ Cj
|.
18 / 47
Introduction Properties of WL
Coarsest Equitable Partition
Let {C1, C2, . . . , Cs} of V(G) be an equitable partition, i.e., for all i and j
and for all u, v ∈ Ci we have: |N(u) ∩ Cj
| = |N(v) ∩ Cj
|.
Lemma (Ramana, Scheinerman, Ullman 1994)
The Weisfeiler-Leman algorithm applied to graph G leads to the
coarsest equitable partition.
(without proof)
18 / 47
Introduction Properties of WL
Coarsest Equitable Partition
Let {C1, C2, . . . , Cs} of V(G) be an equitable partition, i.e., for all i and j
and for all u, v ∈ Ci we have: |N(u) ∩ Cj
| = |N(v) ∩ Cj
|.
Lemma (Ramana, Scheinerman, Ullman 1994)
The Weisfeiler-Leman algorithm applied to graph G leads to the
coarsest equitable partition.
If the Weisfeiler-Leman algorithm is applied to graphs G and H, and
the two stable partitions ρG and ρH are identical, then G and H have
a common coarsest equitable partition.
(without proof)
18 / 47
Introduction Efficient WL Algorithm
1 Introduction
Original Weisfeiler-Leman Algorithm
Properties of the WL Algorithm
Efficient WL Algorithm
2 k-dimensional WL Algorithm on Sets
3 Local k-WL on Sets
4 WL for Data Analysis
Classification with WL
19 / 47
Introduction Efficient WL Algorithm
Weisfeiler-Leman Algorithm
WL-Algorithm
Initial: All vertices v have the same color.
Iteration: Further separation of identically colored vertex sets based
on color histograms of neighbors.
G H G H G H
Initialization Iteration 1 Iteration 2
A naive implementation needs time O(|V|
3
) for a graph G = (V, E), since
we may need up to |V| iterations and every iteration may need O(|V|
2
)
time. It is also possible to realize each iteration in O(|E|) time leading to
O(|V||E|) altogether. ⇒ NEXT: O(|V|
2
log |V|) time implementation
19 / 47
Introduction Efficient WL Algorithm
Key Idea of the Algorithm
‘Processing the smaller half ’ by Hopcroft
1 Iteration: Pick a refining color R from a queue Q
2 for all color classes S with neighbors in R:
3 start a refining operation (R, S)
4 assign new colors to the new subsets of S
5 add all the new color classes but the largest one to the queue Q
G H G H G H
Initialization Iteration 1 Iteration 2
20 / 47
Introduction Efficient WL Algorithm
Pseudocode by Grohe et al. 2017
21 / 47
Introduction Efficient WL Algorithm
Analysis of the Algorithm
Observation of correctness
If we would add all the new color classes to the queue, then the algorithm
is correct (calculated the correct WL color classes).
22 / 47
Introduction Efficient WL Algorithm
Analysis of the Algorithm
Observation of correctness
If we would add all the new color classes to the queue, then the algorithm
is correct (calculated the correct WL color classes).
Correctness of the version with ‘Processing the smaller half’
The algorithm is correct.
22 / 47
Introduction Efficient WL Algorithm
Analysis of the Algorithm
Observation of correctness
If we would add all the new color classes to the queue, then the algorithm
is correct (calculated the correct WL color classes).
Correctness of the version with ‘Processing the smaller half’
The algorithm is correct.
Proof:
22 / 47
Introduction Efficient WL Algorithm
Analysis of the Algorithm
Observation of correctness
If we would add all the new color classes to the queue, then the algorithm
is correct (calculated the correct WL color classes).
Correctness of the version with ‘Processing the smaller half’
The algorithm is correct.
Proof:
Assume that we split cell S into new cells S1, . . . , Sr
, and Sr
is the
largest one not added to Q.
22 / 47
Introduction Efficient WL Algorithm
Analysis of the Algorithm
Observation of correctness
If we would add all the new color classes to the queue, then the algorithm
is correct (calculated the correct WL color classes).
Correctness of the version with ‘Processing the smaller half’
The algorithm is correct.
Proof:
Assume that we split cell S into new cells S1, . . . , Sr
, and Sr
is the
largest one not added to Q.
Consider some (other) cell Ci
. If we first refine Ci with S and then
with S1, . . . , Sr−1, then we have already taken Sr
into account, since
for all v we have: dSr
(v) = dS (v) − (dS1
(v) + dS2
(v) + · · · + dSr−1
(v)),
where dSr
(v) is the number of neighbors of v in cell Sr
22 / 47
Introduction Efficient WL Algorithm
Running Time of the Algorithm
Running time
The algorithm displayed as Pseudocode runs in time O(n
2
log n) on a
graph G = (V, E) with n = |V| vertices.
23 / 47
Introduction Efficient WL Algorithm
Running Time of the Algorithm
Running time
The algorithm displayed as Pseudocode runs in time O(n
2
log n) on a
graph G = (V, E) with n = |V| vertices.
Proof: First we consider one iteration of the while loop:
Line 7: The degree D(v) for all vertices v (number of neighbors of v
of color q) can be calculated by traversing all neighbors of all vertices
in P(q) → runtime in O(n|P(q)|)
23 / 47
Introduction Efficient WL Algorithm
Running Time of the Algorithm
Running time
The algorithm displayed as Pseudocode runs in time O(n
2
log n) on a
graph G = (V, E) with n = |V| vertices.
Proof: First we consider one iteration of the while loop:
Line 7: The degree D(v) for all vertices v (number of neighbors of v
of color q) can be calculated by traversing all neighbors of all vertices
in P(q) → runtime in O(n|P(q)|)
Line 8 (sorting) can be done in linear time using bucket sort
23 / 47
Introduction Efficient WL Algorithm
Running Time of the Algorithm
Running time
The algorithm displayed as Pseudocode runs in time O(n
2
log n) on a
graph G = (V, E) with n = |V| vertices.
Proof: First we consider one iteration of the while loop:
Line 7: The degree D(v) for all vertices v (number of neighbors of v
of color q) can be calculated by traversing all neighbors of all vertices
in P(q) → runtime in O(n|P(q)|)
Line 8 (sorting) can be done in linear time using bucket sort
The recoloring in lines 15-18 runs in linear time O(n)
23 / 47
Introduction Efficient WL Algorithm
Running Time of the Algorithm
Running time
The algorithm displayed as Pseudocode runs in time O(n
2
log n) on a
graph G = (V, E) with n = |V| vertices.
Proof: First we consider one iteration of the while loop:
Line 7: The degree D(v) for all vertices v (number of neighbors of v
of color q) can be calculated by traversing all neighbors of all vertices
in P(q) → runtime in O(n|P(q)|)
Line 8 (sorting) can be done in linear time using bucket sort
The recoloring in lines 15-18 runs in linear time O(n)
⇒ The overall runtime of a vertex v ∈ P(q) during one iteration of the
while loop is bounded by O(n).
23 / 47
Introduction Efficient WL Algorithm
Proof of Running Time ff.
Crucial Observation
Each vertex appears at most O(log n) times in a color class P(q) for some
q taken from Q in line 6.
24 / 47
Introduction Efficient WL Algorithm
Proof of Running Time ff.
Crucial Observation
Each vertex appears at most O(log n) times in a color class P(q) for some
q taken from Q in line 6.
Proof of observation:
Whenever a new color is added to Q in line 12, its color class Bi has
at most half the size of its previous class.
24 / 47
Introduction Efficient WL Algorithm
Proof of Running Time ff.
Crucial Observation
Each vertex appears at most O(log n) times in a color class P(q) for some
q taken from Q in line 6.
Proof of observation:
Whenever a new color is added to Q in line 12, its color class Bi has
at most half the size of its previous class.
Assume that a vertex v appears k times on Q in the colors
q1, q2, . . . , qk . Then qi+1 ≤ qi/2 and thus k ≤ log n.
24 / 47
Introduction Efficient WL Algorithm
Proof of Running Time ff.
Crucial Observation
Each vertex appears at most O(log n) times in a color class P(q) for some
q taken from Q in line 6.
Proof of observation:
Whenever a new color is added to Q in line 12, its color class Bi has
at most half the size of its previous class.
Assume that a vertex v appears k times on Q in the colors
q1, q2, . . . , qk . Then qi+1 ≤ qi/2 and thus k ≤ log n.
Altogether, we have O(n
2
log n), because each iteration requires O(n) time
per vertex in q, and each of the n vertices appears at most log n times.
There is also an implementation with time O((|V| + |E|) log |V|).
[Source of proof: see Grohe et al. 2017]
24 / 47
k-dimensional WL Algorithm on Sets
1 Introduction
Original Weisfeiler-Leman Algorithm
Properties of the WL Algorithm
Efficient WL Algorithm
2 k-dimensional WL Algorithm on Sets
3 Local k-WL on Sets
4 WL for Data Analysis
Classification with WL
25 / 47
k-dimensional WL Algorithm on Sets
k-dimensional Weisfeiler-Leman Algorithm (Sets)
Definition: Two k-vertex sets U, W ⊆ V are called neighbors if they differ
in only one element, i.e. |U ∪ W | = k − 1.
k-WL Algorithm for k-sets
Initial: k-sets U, W ⊆ V get the same color if G[U] ≃ G[W ].
Iteration: Two identically colored k-sets U und W get different
colors if there exists a color c so that U and W have a different
cardinality set of neighbors of color c.
G Initialization 2-WL
25 / 47
k-dimensional WL Algorithm on Sets
k-dimensional Weisfeiler-Leman Algorithm (Sets)
Definition: Two k-vertex sets U, W ⊆ V are called neighbors if they differ
in only one element, i.e. |U ∪ W | = k − 1.
k-WL Algorithm for k-sets
Initial: k-sets U, W ⊆ V get the same color if G[U] ≃ G[W ].
Iteration: Two identically colored k-sets U und W get different
colors if there exists a color c so that U and W have a different
cardinality set of neighbors of color c.
G Initialization 2-WL Iteration 1: 2-WL
25 / 47
k-dimensional WL Algorithm on Sets
k-WL Algorithm
Properties of the k-WL
k-WL (k > 2) is stronger than WL
G Initialization 2-WL Iteration 1: 2-WL
26 / 47
k-dimensional WL Algorithm on Sets
k-WL Algorithm
Properties of the k-WL
k-WL (k > 2) is stronger than WL
exact for large enough k (identifies each graph)
G Initialization 2-WL Iteration 1: 2-WL
26 / 47
k-dimensional WL Algorithm on Sets
k-WL Algorithm
Properties of the k-WL
k-WL (k > 2) is stronger than WL
exact for large enough k (identifies each graph)
graph isomorphism approach by Babai uses k = O(log n)
G Initialization 2-WL Iteration 1: 2-WL
26 / 47
k-dimensional WL Algorithm on Sets
k-WL Algorithm
Properties of the k-WL
k-WL (k > 2) is stronger than WL
exact for large enough k (identifies each graph)
graph isomorphism approach by Babai uses k = O(log n)
there exist graph classes for which k = θ(n) is necessary
G Initialization 2-WL Iteration 1: 2-WL
26 / 47
k-dimensional WL Algorithm on Sets
k-WL Algorithm
Properties of the k-WL
k-WL (k > 2) is stronger than WL
exact for large enough k (identifies each graph)
graph isomorphism approach by Babai uses k = O(log n)
there exist graph classes for which k = θ(n) is necessary
running time: O(k
2
|V|
k+1 log |V|)
G Initialization 2-WL Iteration 1: 2-WL
26 / 47
k-dimensional WL Algorithm on Sets
k-WL Algorithm
k-WL can distinguish regular graphs: k = 3
G H
27 / 47
k-dimensional WL Algorithm on Sets
k-WL Algorithm
k-WL can distinguish regular graphs: k = 3
G H
→ strong for higher k, but also very slow
27 / 47
Local k-WL on Sets
1 Introduction
Original Weisfeiler-Leman Algorithm
Properties of the WL Algorithm
Efficient WL Algorithm
2 k-dimensional WL Algorithm on Sets
3 Local k-WL on Sets
4 WL for Data Analysis
Classification with WL
28 / 47
Local k-WL on Sets
Local k-WL Algorithm (k-LWL)
Idea: Define neighbors of the k-sets depending on graph structure
Two k-sets U und W are neighbors with s ∈ U \ W and t ∈ W \ U
and there exists an edge from s to a vertex in W and an edge from t
to a vertex in U. I.e., ∃u ∈ W : (s, u) ∈ E and ∃v ∈ U : (t, v) ∈ E.
→ takes sparsity of the original graph G = (V, E) into account
→ considers local and global graph properties
G Initialization 2-LWL
Morris, Kersting, Mutzel ICDM 2017, DFG SFB 876: Providing Information by Resource-Constrained Data Analysis
28 / 47
Local k-WL on Sets
Local k-WL Algorithm (k-LWL)
Idea: Define neighbors of the k-sets depending on graph structure
Two k-sets U und W are neighbors with s ∈ U \ W and t ∈ W \ U
and there exists an edge from s to a vertex in W and an edge from t
to a vertex in U. I.e., ∃u ∈ W : (s, u) ∈ E and ∃v ∈ U : (t, v) ∈ E.
→ takes sparsity of the original graph G = (V, E) into account
→ considers local and global graph properties
G Initialization 2-LWL 1. Iteration 2-LWL
Morris, Kersting, Mutzel ICDM 2017, DFG SFB 876: Providing Information by Resource-Constrained Data Analysis
28 / 47
Local k-WL on Sets
Comparison: Local k-LWL vs. k-WL
Running time
k-sets of the k-LWL have much less neighbors
much faster than k-WL
G 2-WL 2-LWL
Morris, Kersting, Mutzel 2017
29 / 47
Local k-WL on Sets
Comparison: Local k-LWL vs. k-WL
Running time
k-sets of the k-LWL have much less neighbors
much faster than k-WL
G 2-WL 2-LWL
Morris, Kersting, Mutzel 2017
29 / 47
Local k-WL on Sets
Comparison of Distinction Power
2-WL: 2 color classes 2-LWL: 2 color classes
Morris, Mutzel
30 / 47
Local k-WL on Sets
Comparison of Distinction Power
2-WL: 2 color classes 2-LWL: 2 color classes
2-WL: 2 color classes 2-LWL: 3 color classes
→2-WL cannot distinguish graphs, but 2-LWL
Morris, Mutzel
30 / 47
Local k-WL on Sets
Comparison: Local k-LWL vs. k-WL
Separation Strength (for connected G)
Morris, Mutzel
31 / 47
Local k-WL on Sets
Comparison: Local k-LWL vs. k-WL
Separation Strength (for connected G)
Morris, Mutzel
31 / 47
Local k-WL on Sets
Comparison: Local k-LWL vs. k-WL
Separation Strength (for connected G)
Morris, Mutzel
31 / 47
Local k-WL on Sets
Comparison: Local k-LWL vs. k-WL
Separation Strength (for connected G)
Local k-LWL refines at least as much as k-WL.
2-WL: 5 color classes 2-LWL: 10 color classes
12, 6, 6, 3, 1 4, 4, 4, 4, 2, 4, 2, 2, 1, 1
Morris, Mutzel
31 / 47
Local k-WL on Sets
Comparison: Local k-LWL vs. k-WL
Separation Strength (for connected G)
Local k-LWL refines at least as much as k-WL.
If k-WL can distinguish two graphs, then also k-LWL.
2-WL: 5 color classes 2-LWL: 10 color classes
12, 6, 6, 3, 1 4, 4, 4, 4, 2, 4, 2, 2, 1, 1
Morris, Mutzel
31 / 47
Local k-WL on Sets
Comparison: Local k-LWL vs. k-WL
Separation Strength (for connected G)
Local k-LWL refines at least as much as k-WL.
If k-WL can distinguish two graphs, then also k-LWL.
Local k-LWL is stronger than k-WL.
2-WL: 5 color classes 2-LWL: 10 color classes
12, 6, 6, 3, 1 4, 4, 4, 4, 2, 4, 2, 2, 1, 1
Morris, Mutzel
31 / 47
Local k-WL on Sets
Comparison: Local k-LWL vs. k-WL
Separation Strength (for connected G)
Local k-LWL refines at least as much as k-WL.
If k-WL can distinguish two graphs, then also k-LWL.
Local k-LWL is stronger than k-WL.
Sherali-Adams Relaxation of k-LWL is stronger than that of k-WL.
2-WL: 5 color classes 2-LWL: 10 color classes
12, 6, 6, 3, 1 4, 4, 4, 4, 2, 4, 2, 2, 1, 1
Morris, Mutzel
31 / 47
Local k-WL on Sets
Cai, Furer, Immerman - Graphs for lower bound ¨
32 / 47
Local k-WL on Sets
Cai, Furer, Immerman - Graphs for lower bound ¨
2-WL: 4 color classes 2-LWL: 5 color classes
32 / 47
Local k-WL on Sets
Cai, Furer, Immerman - Graphs for lower bound ¨
2-WL: 4 color classes 2-LWL: 5 color classes
2-WL: 4 color classes 2-LWL: 11 color classes
→2-WL cannot distinguish graphs, but 2-LWL
32 / 47
Local k-WL on Sets
Immerman, Grohe - Graphs for lower bound
2-WL: 2 color classes 2-LWL: 15 color classes
33 / 47
Local k-WL on Sets
Immerman, Grohe - Graphs for lower bound
2-WL: 2 color classes 2-LWL: 15 color classes
2-WL: 2 color classes 2-LWL: 15 color classes
→ 2-LWL refines more but unfortunately does not distinguish
33 / 47
Local k-WL on Sets
Overview of k-dimensional WL versions
k-WL sets
local k-WL sets
k-WL tuples:
k-FWL tuples:
local k-WL tuples
local k-FWL tuples
34 / 47
Local k-WL on Sets
Overview of k-dimensional WL versions
k-WL sets
local k-WL sets
k-WL tuples:
k-FWL tuples:
local k-WL tuples
local k-FWL tuples
In addition: version analyzed by Malkin (2014): count local neighborhood
and global neighborhood separately:
Malkin k-WL tuples: g/
Malkin k-FWL tuples
34 / 47
Local k-WL on Sets
Discriminatory Power of k-WL versions (tupel)
So far: k-sets, but k-tupels are stronger
G: global neighborhood, L/G: both neighborhoods (Malkin), L: local
A ≡ B: A is at least as strong as B, A ⋨ B: stronger
Two different definitions of the k-WL: w: weak, s: strong
Morris, Rattan, Mutzel: NeurIPs 2020 35 / 47
Local k-WL on Sets
Discriminatory Power of k-WL versions
G: global neighborhood, L/G: both neighborhoods, L: local
A ≡ B: A is at least as strong as B, A ⋨ B: stronger
Two different definitions of the k-WL: w: weak, s: strong
Morris, Rattan, Mutzel: NeurIPs 2020
36 / 47
Local k-WL on Sets
Connections of WL to other fields
Connections to
descriptive complexity
k-pebble counting games
counting homomorphisms
Sherali-Adams relaxation of the natural ILP
Gr¨obner basis
graph neural networks (deep learning)
37 / 47
WL for Data Analysis
1 Introduction
Original Weisfeiler-Leman Algorithm
Properties of the WL Algorithm
Efficient WL Algorithm
2 k-dimensional WL Algorithm on Sets
3 Local k-WL on Sets
4 WL for Data Analysis
Classification with WL
38 / 47
WL for Data Analysis
WL for Data Analysis
WL for Data Analysis
38 / 47
WL for Data Analysis Classification with WL
Classification (Supervised Learning)
Given: Training set with labelled items (classes).
Goal: Train a classifier so that a new item will be assigned to its correct
class.
Sources: towardsdatascience.com/, www.ritchieng.com/logistic-regression/, medium.freecodecamp.org/
39 / 47
WL for Data Analysis Classification with WL
Graph (Dataset) Classification
feature vector feature space
Generate a feature vector for each graph in the graph data set
Use your favorite (data) classification method
Sources: https://www.kdd.org/kdd2019/accepted-papers/view/learning-interpretable-metric-between-graphs-convexformulation-and-computa
40 / 47
WL for Data Analysis Classification with WL
Classification with WL, k-WL, k-LWL
Idea: Combination of WL with similarity measures
Construct feature vector for each graph
e.g. after each round: sort the vertices according to colors, vector gets
information of number of vertices with color c
append these (possibly weighted) vectors to each other
Φ(G) = (3, 1, 1) Φ(H) = (3, 1, 1)
41 / 47
WL for Data Analysis Classification with WL
Classification with WL, k-WL, k-LWL
Idea: Combination of WL with similarity measures
Construct feature vector for each graph
e.g. after each round: sort the vertices according to colors, vector gets
information of number of vertices with color c
append these (possibly weighted) vectors to each other
Φ(G) = (3, 1, 1) Φ(H) = (3, 1, 1) Φ(G) = (3, 1, 1, 2, 0, 0, 1, 1, 1, 0) Φ(H) = (3, 1, 1, 2, 1, 1, 0, 0, 0, 1)
41 / 47
WL for Data Analysis Classification with WL
Classification with WL, k-WL, k-LWL
Idea: Combination of WL with similarity measures
Construct feature vector for each graph
e.g. after each round: sort the vertices according to colors, vector gets
information of number of vertices with color c
append these (possibly weighted) vectors to each other
Φ(G) = (3, 1, 1) Φ(H) = (3, 1, 1) Φ(G) = (3, 1, 1, 2, 0, 0, 1, 1, 1, 0) Φ(H) = (3, 1, 1, 2, 1, 1, 0, 0, 0, 1)
→ Similarity measure based on graph kernel, Jaccard-Coefficient, ...
41 / 47
WL for Data Analysis Classification with WL
Classification with WL, k-WL, k-LWL
Similarity score between each pair of graphs
Let Φi
t
(Gi) be the feature vector for each graph Gi of round t
we define: Φt(Gi) = [Φ0(Gi), . . . , Φt(Gi)]
Weisfeiler-Leman subtree graph kernel for t rounds:
kt(Gi
, Gj) = ⟨Φt(Gi), Φt(Gj)⟩
⇒ leads to a (normalized) gram matrix
use this as input to a SVM (kernel trick)
Φ1(G) = (3, 1, 1) Φ1(H) = (3, 1, 1)
42 / 47
WL for Data Analysis Classification with WL
Classification with WL, k-WL, k-LWL
Similarity score between each pair of graphs
Let Φi
t
(Gi) be the feature vector for each graph Gi of round t
we define: Φt(Gi) = [Φ0(Gi), . . . , Φt(Gi)]
Weisfeiler-Leman subtree graph kernel for t rounds:
kt(Gi
, Gj) = ⟨Φt(Gi), Φt(Gj)⟩
⇒ leads to a (normalized) gram matrix
use this as input to a SVM (kernel trick)
Φ1(G) = (3, 1, 1) Φ1(H) = (3, 1, 1) Φ2(G) = (2, 0, 0, 1, 1, 1, 0) Φ2(H) = (2, 1, 1, 0, 0, 0, 1)
42 / 47
WL for Data Analysis Classification with WL
Scalability: sampling for local k-LWL Algorithm
Idea: Increase scalability by sampling
Sample a subset of the k-sets
Explore the t-neighborhood around these sets
Run the local k-LWL on each of the t-neighborhoods
Lemma (Morris, Kersting, M. 2017)
These k-sets get the same color as the k-LWL after t rounds.
43 / 47
WL for Data Analysis Classification with WL
Approximation Result
Theorem (Morris, Kersting, M. 2017)
Let G be a d-bounded degree graph and ϵ ∈ (0, 1].
Then for every number of iterations t of the local k-LWL, there exists
an adaptive sampling algorithm which approximates the normalized
feature vector of the local k-LWL on t iterations up to ϵ with
probability (1 − δ) for δ ∈ (0, 1).
The running time only depends on d, k, δ, ϵ and t (not on the graph
size V).
Such a result is not possible for the k-WL.
44 / 47
WL for Data Analysis Classification with WL
Evaluation of the k-LWL (Graph Kernel, SVM)
Protein interaction networks (ENZYMES)
Molecule data bases (MUTAG)
Cancer data sets (NCI1, NCI109)
Social networks (IMDB-BIN, REDDIT-BIN)
Morris, Kersting, Mutzel ICDM 2017
45 / 47
WL for Data Analysis Classification with WL
Comparison of WL with other graph kernels
Experimental comparison of 13 different graph kernels
4 WL variants, one based on message passing
4 variants with shortest paths and random walks
multiscale Laplacian
subgraph matching, graphlet
pure histograms (vertices, edges)
41 benchmark data sets from the TU Dataset: Social networks, molecule
graphs, bioinformatics, computer vision
Borgwardt et al.: Graph Kernels: State-of-the-Art and future Challenges, Nov. 2020
46 / 47
WL for Data Analysis Classification with WL
Selection of Graph Kernels [Borgwardt et al. 2020]
Graph types: (i) fully unlabeled, (ii) node labels, (iii) fully labelled: node+edge labels, (iv) only
node attributes, (v) full node information, (vi) everything but node attributes
Methods: H: histograms, SP: shortest paths, WL: Weisfeiler-Leman, HGK: hash graph kernel
with WL, MP: message parsing based on WL
Source: Borgwardt et al.: Graph Kernels: State-of-the-Art and future Challenges, S. 124, Nov. 2020 47 / 47